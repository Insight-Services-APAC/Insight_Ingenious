{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Insight Services APAC - AI Collateral Documentation","text":"<p>\"Accelerating time-to-value for Generative AI Projects.\"</p>"},{"location":"#mission-statement","title":"Mission Statement","text":"<p>Welcome to the Insight Services APAC documentation,  designed to guide you in developing and deploying Generative AI projects. Our goal is to provide a clear roadmap to accelerate your time-to-value, with a strong focus on business outcomes and production-ready architectures.</p> <ul> <li> Industry-Specific Workflow Solutions: Pre-built workflows for common use cases (e.g., curriculum planning for education).</li> </ul>"},{"location":"#key-technologies","title":"Key Technologies","text":"<ul> <li> <p>Microsoft Autogen \u2013 A robust orchestration framework designed to streamline the creation and deployment of multi-agent Generative AI systems.</p> </li> <li> <p>Chainlit \u2013 A framework for developing and deploying multi-agent systems with a focus on ease of use and rapid prototyping.</p> </li> <li> <p>Landing Zone Deployments: Using Bicep or Terraform for automated deployments.</p> </li> </ul>"},{"location":"developer_guide/","title":"Developer Guide","text":"<p>Please use this to guide through our framework (revise this sentence)</p>"},{"location":"developer_guide/#autogen-multi-agent-conversation-framework","title":"AutoGen: Multi-Agent Conversation Framework","text":"<p>AutoGen offers a unified multi-agent conversation framework as a high-level abstraction of using foundation models. It features capable, customizable, and conversable agents which integrate LLMs, tools, and humans via automated agent chat. By automating chat among multiple agents, one can easily make them collectively perform tasks autonomously or with human feedback, including tasks that require using tools via code.</p> <p>This framework simplifies the orchestration, automation, and optimization of a complex LLM workflow. It maximizes the performance of LLM models and overcomes their weaknesses. It enables building next-gen LLM applications based on multi-agent conversations with minimal effort.</p> <p>AutoGen abstracts and implements conversable agents designed to solve tasks through inter-agent conversations. Specifically, the agents in AutoGen have the following features:</p> <ul> <li>Conversable: Agents in AutoGen can send and receive messages to initiate or continue a conversation.</li> <li>Customizable: Agents can be customized to integrate LLMs, humans, tools, or a combination of these.</li> </ul> <p>The figure below shows the built-in agents in AutoGen. </p>"},{"location":"developer_guide/#insight-service-prefabs","title":"Insight Service Prefabs","text":"<p>We have designed a generic service framework -service prefabs- that can let agents converse with each other through message exchanges to jointly finish a task. Different prefabs can perform different actions after receiving messages.</p> <p>You can locate them under <code>services/chat_services</code> folder structure.</p> view service prefabs<pre><code>.\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 chat_service.py\n\u251c\u2500\u2500 chat_services\n\u2502  \u251c\u2500\u2500 __init__.py\n\u2502  \u251c\u2500\u2500 fast_agent\n\u2502  \u2502  \u2514\u2500\u2500 __init__.py\n\u2502  \u2514\u2500\u2500 multi_agent\n\u2502      \u251c\u2500\u2500 __init__.py\n\u2502      \u251c\u2500\u2500 tool_factory.py\n\u2502      \u251c\u2500\u2500 agents\n\u2502      \u251c\u2500\u2500 conversation_flows\n\u2502      \u251c\u2500\u2500 conversation_patterns\n\u2502      \u2514\u2500\u2500 service.py\n\u251c\u2500\u2500 message_feedback_service.py\n\u2514\u2500\u2500 tool_service.py\n</code></pre> <p>Each prefab has 2 components </p> <ul> <li>conversation_flows</li> <li>conversation_patterns</li> </ul>"},{"location":"developer_guide/applications_setup/","title":"Applications Required for Development","text":"<p>This section outlines the applications required for developing using the dbt framework, and provides instructions for both macOS and Windows. The applications include:</p> <ul> <li>Python (latest version)</li> <li>Visual Studio Code or PyCharm</li> <li>Git for Windows/macOS</li> </ul>"},{"location":"developer_guide/applications_setup/#install-python-312","title":"Install Python 3.12","text":""},{"location":"developer_guide/applications_setup/#macos","title":"macOS","text":"<ol> <li>Open your Terminal (you can find it by searching in Spotlight or navigating to <code>/Applications/Utilities/Terminal.app</code>).</li> <li>Install Python 3.12 using Homebrew (make sure Homebrew is installed). Run the following command:    <pre><code>brew install python@3.12\n</code></pre></li> <li>Once installation is complete, verify the installation by running:    <pre><code>python3 --version\n</code></pre>    You should see <code>Python 3.12.x</code> as the output.</li> </ol>"},{"location":"developer_guide/applications_setup/#windows","title":"Windows","text":"<ol> <li>Open PowerShell as an Administrator (press <code>WindowsKey + X</code>, then select PowerShell (Admin)).</li> <li>Download and install Python 3.12 from the official Python website by running:    <pre><code>Invoke-WebRequest -Uri https://www.python.org/ftp/python/3.12.0/python-3.12.0-amd64.exe -OutFile python-3.12.0.exe\nStart-Process -FilePath .\\python-3.12.0.exe -ArgumentList '/quiet InstallAllUsers=1 PrependPath=1' -Wait\n</code></pre></li> <li>After installation, verify the installation by running:    <pre><code>python --version\n</code></pre>    You should see <code>Python 3.12.x</code> as the output.</li> </ol>"},{"location":"developer_guide/applications_setup/#install-visual-studio-code-or-pycharm","title":"Install Visual Studio Code or PyCharm","text":""},{"location":"developer_guide/applications_setup/#macos_1","title":"macOS","text":"<ol> <li>Open Terminal and install Visual Studio Code using Homebrew:    <pre><code>brew install --cask visual-studio-code\n</code></pre>    Alternatively, you can download and install it manually from Visual Studio Code.</li> <li>To verify installation, launch Visual Studio Code from the Terminal:    <pre><code>code .\n</code></pre></li> </ol>"},{"location":"developer_guide/applications_setup/#windows_1","title":"Windows","text":"<ol> <li>Download Visual Studio Code from Visual Studio Code.</li> <li>Install it by following the default installation options.</li> <li>After installation, you can open PowerShell and type:    <pre><code>code .\n</code></pre></li> </ol>"},{"location":"developer_guide/applications_setup/#install-git","title":"Install Git","text":""},{"location":"developer_guide/applications_setup/#macos_2","title":"macOS","text":"<ol> <li>Open Terminal and install Git using Homebrew:    <pre><code>brew install git\n</code></pre></li> <li>After installation, confirm Git is installed by running:    <pre><code>git --version\n</code></pre></li> </ol>"},{"location":"developer_guide/applications_setup/#windows_2","title":"Windows","text":"<ol> <li>Open PowerShell and download Git using the following command:    <pre><code>Invoke-WebRequest -Uri https://github.com/git-for-windows/git/releases/download/v2.42.0.windows.1/Git-2.42.0-64-bit.exe -OutFile git-installer.exe\nStart-Process -FilePath .\\git-installer.exe -ArgumentList '/SILENT' -Wait\n</code></pre></li> <li>Verify the installation by running:    <pre><code>git --version\n</code></pre></li> </ol> <p>Once Git is installed, configure it to use Visual Studio Code as your default editor and set the terminal to use PowerShell (on Windows) or Terminal (on macOS).</p>"},{"location":"developer_guide/applications_setup/#macos-git-configuration","title":"macOS Git Configuration","text":"<ol> <li>Open Terminal and configure Git to use Visual Studio Code as the default editor:    <pre><code>git config --global core.editor \"code --wait\"\n</code></pre></li> </ol>"},{"location":"developer_guide/applications_setup/#windows-git-configuration","title":"Windows Git Configuration","text":"<ol> <li>Open PowerShell and configure Git to use Visual Studio Code as the default editor:    <pre><code>git config --global core.editor \"code --wait\"\n</code></pre></li> <li>Ensure Git uses PowerShell by running:    <pre><code>git config --global core.autocrlf true\n</code></pre></li> </ol> <p>The rest of the installation options should be standard unless you need to change them for other reasons.</p>"},{"location":"developer_guide/folder_structure/","title":"Repo Folder Structure","text":"<p>The <code>__init__.py</code> enables namespace packages, a feature where multiple directories can contribute to a single package.  It essentially extends the package\u2019s <code>__path__</code> to allow Python to combine code from different locations  in the file system under the same package name.</p> View the Folder Structure<pre><code>.\n\u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 __init__.cpython-312.pyc\n\u2502   \u2514\u2500\u2500 dependencies.cpython-312.pyc\n\u251c\u2500\u2500 api\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 routes\n\u251c\u2500\u2500 chainlit\n\u2502   \u2514\u2500\u2500 datalayer.py\n\u251c\u2500\u2500 cli.py\n\u251c\u2500\u2500 config\n\u2502   \u251c\u2500\u2500 config.py\n\u2502   \u2514\u2500\u2500 profile.py\n\u251c\u2500\u2500 core\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 logging.py\n\u251c\u2500\u2500 db\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 chat_history_repository.py\n\u2502   \u251c\u2500\u2500 cosmos\n\u2502   \u251c\u2500\u2500 duckdb\n\u2502   \u2514\u2500\u2500 sqlite\n\u251c\u2500\u2500 dependencies.py\n\u251c\u2500\u2500 errors\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 __pycache__\n\u2502   \u251c\u2500\u2500 content_filter_error.py\n\u2502   \u2514\u2500\u2500 token_limit_exceeded_error.py\n\u251c\u2500\u2500 external_services\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 __pycache__\n\u2502   \u251c\u2500\u2500 openai_service.py\n\u2502   \u2514\u2500\u2500 search_service.py\n\u251c\u2500\u2500 main.py\n\u251c\u2500\u2500 models\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 __pycache__\n\u2502   \u251c\u2500\u2500 chat.py\n\u2502   \u251c\u2500\u2500 database_client.py\n\u2502   \u251c\u2500\u2500 http_error.py\n\u2502   \u251c\u2500\u2500 message.py\n\u2502   \u251c\u2500\u2500 message_feedback.py\n\u2502   \u251c\u2500\u2500 search.py\n\u2502   \u2514\u2500\u2500 tool_call_result.py\n\u251c\u2500\u2500 services\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 chat_service.py\n\u2502   \u251c\u2500\u2500 chat_services\n\u2502   \u251c\u2500\u2500 message_feedback_service.py\n\u2502   \u2514\u2500\u2500 tool_service.py\n\u2514\u2500\u2500 utils\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 conversation_builder.py\n    \u251c\u2500\u2500 prompt_templates.py\n    \u2514\u2500\u2500 token_counter.py\n</code></pre>"},{"location":"developer_guide/package_install/","title":"Package Installation","text":"<p>Follow these steps to set up the Ingenious package locally:</p> <ol> <li> <p>Clone the repository:     <pre><code>git clone &lt;repository-url&gt;\n</code></pre></p> </li> <li> <p>Navigate to the repository:     <pre><code>cd ingenious\n</code></pre></p> </li> <li> <p>Create a virtual environment:     <pre><code>python -m venv .venv\n</code></pre></p> </li> <li> <p>Activate the virtual environment:</p> <ul> <li>On Windows:   <pre><code>.venv\\Scripts\\activate\n</code></pre></li> <li>On macOS/Linux:   <pre><code>source .venv/bin/activate\n</code></pre></li> </ul> </li> <li> <p>Install the dependencies:     <pre><code>pip install -r requirements.txt\n</code></pre></p> </li> </ol>"},{"location":"documentation_guide/","title":"Documentation Guide","text":""},{"location":"documentation_guide/#building-you-environment","title":"Building you environment","text":"<p>Documentation for this project is built using mkdocs-material. To contribute to the documentation you will need to create a separate python environment. I suggest that you call this <code>.env_mkdocs</code> to avoid confusion with the dbt environment. Create your environment and install the required packages as shown below:</p> <p>Important</p> <p>The commands below assume that you have already performed the <code>Core Tools Installation</code> steps in the User Guide. If you have not done this yet, please do so before proceeding. Note you ONLY have to install <code>core tools</code> it is not necessary to move on to the <code>other tools</code> section. </p> Create and activate the Python environment<pre><code># Create and activate the Python environment\n#MacOS\npython -m venv .env_mkdocs\nsource .env_mkdocs/bin/activate\npip install -r ./requirements_mkdocs.txt\n\nWidnows\n.\\.env_mkdocs\\Scripts\\activate.ps1\npip install -r ./requirements_mkdocs.txt\n</code></pre>"},{"location":"documentation_guide/#updating-the-documentation","title":"Updating the documentation","text":"<p>The docucementation source is held in the <code>docs</code> directory. To update the documentation you will need to edit the markdown files in this directory. In order to understand the syntax used for the markdown be sure to review the reference section for mkdocs-material. Once you have made your changes you can build the documentation using the command below:</p> Build the documentation<pre><code>mkdocs build\n</code></pre> <p>To view the documentation locally you can use the command below:</p> View the documentation locally<pre><code>mkdocs serve\n</code></pre> <p>Tip</p> <p>The <code>mkdocs serve</code> command will start a local web server that will allow you to view the documentation in your browser. The server will also automatically rebuild the documentation when you make changes to the source files.</p> <p>Before publishing the documentation you should ensure that the documentation is up to date and that the changes are correct. You should also pull the latest from the repository to ensure that you are not overwriting someone else's changes. Do this by running the command below:</p> Pull the latest changes from the repository<pre><code>git pull\n</code></pre> <p>You can now publish the documentation to the repository by running the command below:</p> Publish the documentation<pre><code>mkdocs gh-deploy  --remote-name \"https://${GH_TOKEN}@github.com/Insight-Services-APAC/Insight_Ingenious.git\"\n</code></pre>"},{"location":"user_guide/","title":"User Guide","text":""},{"location":"user_guide/development_workflow/","title":"Development Workflow","text":""},{"location":"user_guide/development_workflow/#development-and-deployment-flow-using-fabric-spark-notebook-adapter","title":"Development and Deployment Flow Using Fabric Spark Notebook Adapter","text":"<p>Advantages</p> <ul> <li> Available today</li> <li> Native Fabric Notebooks Generated and Deployed<ol> <li>Non dbt users able to view notebooks and business logic</li> <li>Monitoring and debugging of loads directly in Fabric without the need for a separate tool</li> </ol> </li> <li> Re-occurring loads achieved using native Fabric scheduling </li> <li> Simplified code promotion process using native Fabric Git integration</li> <li> No need for dbt hosted in a virtual machine <ol> <li>No need for service account</li> <li>No need for Azure Landing Zone</li> <li>No need for secure network connectivity between Azure VM and Fabric   </li> </ol> </li> <li> Allows for disconnected development environment providing<ol> <li>Faster DBT build times</li> <li>Greater developer flexibility</li> </ol> </li> <li> Simplified code promotion Process using native Fabric Git integration<ol> <li>Single, native promotion process for all Fabric artifacts including non-dbt ones</li> </ol> </li> </ul> <p>Disadvantages</p> <ul> <li>Requires Additional Steps<ol> <li>Meta Data Extract</li> <li>Notebook Upload </li> <li>Notebook Import</li> </ol> </li> </ul>"},{"location":"user_guide/development_workflow/#development-and-deployment-flow-using-original-fabric-spark-adapter","title":"Development and Deployment Flow Using Original Fabric Spark Adapter","text":""},{"location":"user_guide/development_workflow/#detailed-workflow","title":"Detailed Workflow","text":"<p>Inital Setup 1. Provision Workspace    - Development Environment: Fabric Portal    - Re-occurence: Do once per development environment set-up    - Instructions: Create a new workspace in the Power BI Portal, or use an existing workspace.</p> <ol> <li>Get Workspace Connection Details</li> <li>Development Environment: Fabric Portal</li> <li>Re-occurence: Do once per development environment set-up</li> <li> <p>Instructions: Get the workspace connection details from the Power BI Portal.</p> </li> <li> <p>Create or Update <code>profiles.yml</code></p> </li> <li>Development Environment: VS Code on local, developemnt machine</li> <li></li> <li> <p>Create or Update <code>dbt_project.yml</code> </p> </li> <li>Build Project</li> <li>Manually Upload Notebooks </li> <li>Run Meta Data Extract</li> </ol> <p>Ongoing Development Cycle</p> <ol> <li> <p>Download Metadata: </p> </li> <li> <p>Update Dbt Project </p> </li> <li>Build Dbt Project </li> <li>Verify Outputs </li> <li>Update Notebooks     <ol> <li>Upload to Onelake</li> <li>Update to GIT repo</li> </ol> </li> <li>Promote to Workspace     <ol> <li>Run Import Notebook</li> <li>Promote GIT branch</li> </ol> </li> <li>Run Master Notebook </li> <li>Validate Results </li> <li>Run Metadata Extract</li> </ol>"},{"location":"user_guide/fabric_ci_cd_process/","title":"Fabric CI/CD with Git Deployment","text":""},{"location":"user_guide/fabric_ci_cd_process/#git-based-deployment","title":"Git Based Deployment","text":"<p>The initial setup is based on a Git branch that is linked to all workspaces. As illustrated in the given example, we have described three stages: Development, Test, and Production. It also employs feature branches for individual developments within isolated workspaces using branch out functionality.</p> <p>The successful operation of this scenario depends on branching, merging, and pull requests.</p> <ol> <li><code>Each workspace is assigned its own branch.</code></li> <li><code>The introduction of new features is facilitated by raising pull requests.</code></li> <li><code>All deployments are initiated from the repository.</code></li> <li><code>To transition from Development to Test, and subsequently from Test to Production, a pull request must be initiated from the originating stage.</code></li> </ol> <p>The synchronization between the Git branch and the workspace can be automated. This is achieved by invoking the Git Sync API as part of a build pipelines, which is automatically triggered following the approval of a pull request.</p> <p></p>"},{"location":"user_guide/fabric_ci_cd_process/#git-and-build-environment-based-deployment","title":"Git and Build Environment Based Deployment","text":"<p>Git is exclusively linked to the Development workspace. The deployment to other stages is executed based on Build environments. This implies that the Fabric Item APIs are utilized to perform Create, Read, Update or Delete operations.</p> <p>Key points of this setup are:</p> <ol> <li><code>The Git repository serves as the foundation for creating, updating, or deleting items in the workspace.</code></li> <li><code>Git is solely connected to the Development workspace.</code></li> <li><code>Following a pull request, a Build pipeline is activated.</code></li> <li><code>The Build pipeline executes operations to the workspace.</code></li> </ol> <p>Note</p> <pre><code>This approach is code-intensive and for each future item to be supported, modifications may be required in the Build pipelines.\n</code></pre> <p></p>"},{"location":"user_guide/fabric_ci_cd_process/#git-and-fabric-deployment-pipeline-based-deployment","title":"Git and Fabric Deployment Pipeline Based Deployment","text":"<p>This is based on Fabric Deployment pipelines. This user-friendly interface simplifies the deployment process from one stage to another and is less code-intensive.</p> <p>Git is solely connected to the Development workspace, and feature branches continue to exist in separate workspaces. However, the Test, Production, and any additional workspaces are not linked to Git.</p> <p>Key aspects of this setup include:</p> <ol> <li><code>The release process to other stages, such as Test and Production, is managed via Deployment Pipelines in the Fabric.</code></li> <li><code>The Development workspace is the only one connected to Git.</code></li> <li><code>Triggers for the Fabric deployment pipeline can be automated. This is achieved by using Build Pipelines, which are automatically activated following the approval of a pull request.</code></li> </ol> <p>These pipelines can call the Fabric REST API and can also be integrated with Git Sync API for synchronizing the development workspace.</p> <p></p>"},{"location":"user_guide/initial_setup/","title":"Environment Setup","text":"<p>This section outlines the steps required to setup the development environment to use this dbt-adapter as part of a dbt data transformation project.</p> <p>To provide a common, cross-platform set of instructions we will first install Powershell. To facilitate the installation process we will use package managers such as winget for Windows, brew for MacOS and <code>apt</code> for Linux.</p>"},{"location":"user_guide/initial_setup/#core-tools-installation","title":"Core Tools Installation","text":"WindowsMacOSLinux <pre><code># Winget Installs \nwinget install Microsoft.PowerShell\n</code></pre> <pre><code>brew install powershell/tap/powershell\n</code></pre> <pre><code># TBA\n</code></pre> <p>Next we will install Python and development tools such as vscode.</p> WindowsMacOSLinux <pre><code># Winget Installs \nwinget install -e --id Python.Python -v 3.12\nwinget install -e --id Microsoft.VisualStudioCode\nwinget install --id Git.Git -e --source winget\n\n# Python Environment Manager\nPython -m pip install --user virtualenv\n</code></pre> <pre><code># Brew Installs\nbrew install python@3.12\nbrew install --cask visual-studio-code\nbrew install git\n\n# Python Environment Manager\nPython -m pip install --user virtualenv\n\n# TODO \n# Add OSX AZ Copy Instructions\n</code></pre> <pre><code># TBA\n</code></pre>"},{"location":"user_guide/initial_setup/#other-tools","title":"Other tools","text":"<p>Now that we have pwsh installed, we can use it as a cross platform shell to install the additional required tools. </p> WindowsMacOSLinux <pre><code># Az Copy Install - No Winget Package Available\nInvoke-WebRequest -Uri https://aka.ms/downloadazcopy-v10-windows -OutFile AzCopy.zip -UseBasicParsing\nExpand-Archive ./AzCopy.zip ./AzCopy -Force\nNew-Item -ItemType \"directory\" -Path \"$home/AzCopy\"  -Force  \nGet-ChildItem ./AzCopy/*/azcopy.exe | Move-Item -Destination \"$home\\AzCopy\\AzCopy.exe\" -Force  \n$userenv = [System.Environment]::GetEnvironmentVariable(\"Path\", \"User\") \n[System.Environment]::SetEnvironmentVariable(\"PATH\", $userenv + \";$home\\AzCopy\", \"User\")\nRemove-Item .\\AzCopy\\ -Force\nRemove-Item AzCopy.zip -Force\n</code></pre> <pre><code># TODO \n# Add OSX AZ Copy Instructions\n</code></pre> <pre><code># TBA\n</code></pre>"},{"location":"user_guide/initial_setup/#source-directory-python-env","title":"Source Directory &amp; Python Env","text":"<p>Now lets create and activate our Python environment and install the required packages.</p> <p>Tip</p> <p>When doing pip install dbt-fabricspark below it can take a few minutes to complete on some machines. Occasionally pip may get stuck and in such cases break the execution using ctrl-c and run the same pip again. </p> WindowsMacOSLinux <pre><code># Ensure that you are in the pwsh shell\npwsh\n\n# Create a new source code directory\nmkdir dbt-fabricsparknb-test #Note that the name of the directory is arbitrary... call it whatever you like\n# Navigate to the new directory\ncd dbt-fabricsparknb-test\n\n# Create and activate the Python environment\npython -m venv .env\n./.env/Scripts/Activate.ps1\n\n# Install the dbt-fabricsparknb package from the repository\npip install --upgrade git+https://github.com/Insight-Services-APAC/APAC-Capability-DAI-DbtFabricSparkNb\n</code></pre> <pre><code># Ensure that you are in the pwsh shell\npwsh\n\n# Create a new source code directory\nmkdir dbt-fabricsparknb-test #Note that the name of the directory is arbitrary... call it whatever you like\n# Navigate to the new directory\ncd dbt-fabricsparknb-test\n\n# Create and activate the Python environment\npython -m venv .env\n./.env/Scripts/Activate.ps1  \n\n# Install the dbt-fabricsparknb package from the repository\npip install --upgrade git+https://github.com/Insight-Services-APAC/APAC-Capability-DAI-DbtFabricSparkNb\n</code></pre> <pre><code># TBA\n</code></pre> <p>Info</p> <p>You are now ready to move to the next step in which you will set up your dbt project. Follow the Dbt Project Setup guide.</p>"}]}